{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Feature Selection\n",
    "### Test different algorithmic functions to see which set of features will yeild better accuracy without overfitting the model. It will also reduce training time because of less data to process.\n",
    "#### Credit to Jason Brownlee's [article](https://machinelearningmastery.com/feature-selection-machine-learning-python/) for guidance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Extra Tree Classifier\n",
    "Feature Importance with Bagged decision trees like Random Forest and Extra Trees can be used to esmiate the importance of features. \n",
    "\n",
    "Learn more about the [ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html) class in the scikit-learn API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n       'koi_kepmag'],\n      dtype='object')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>koi_disposition</th>\n      <th>koi_fpflag_nt</th>\n      <th>koi_fpflag_ss</th>\n      <th>koi_fpflag_co</th>\n      <th>koi_fpflag_ec</th>\n      <th>koi_period</th>\n      <th>koi_period_err1</th>\n      <th>koi_period_err2</th>\n      <th>koi_time0bk</th>\n      <th>koi_time0bk_err1</th>\n      <th>...</th>\n      <th>koi_steff_err2</th>\n      <th>koi_slogg</th>\n      <th>koi_slogg_err1</th>\n      <th>koi_slogg_err2</th>\n      <th>koi_srad</th>\n      <th>koi_srad_err1</th>\n      <th>koi_srad_err2</th>\n      <th>ra</th>\n      <th>dec</th>\n      <th>koi_kepmag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>54.418383</td>\n      <td>2.479000e-04</td>\n      <td>-2.479000e-04</td>\n      <td>162.513840</td>\n      <td>0.003520</td>\n      <td>...</td>\n      <td>-81</td>\n      <td>4.467</td>\n      <td>0.064</td>\n      <td>-0.096</td>\n      <td>0.927</td>\n      <td>0.105</td>\n      <td>-0.061</td>\n      <td>291.93423</td>\n      <td>48.141651</td>\n      <td>15.347</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19.899140</td>\n      <td>1.490000e-05</td>\n      <td>-1.490000e-05</td>\n      <td>175.850252</td>\n      <td>0.000581</td>\n      <td>...</td>\n      <td>-176</td>\n      <td>4.544</td>\n      <td>0.044</td>\n      <td>-0.176</td>\n      <td>0.868</td>\n      <td>0.233</td>\n      <td>-0.078</td>\n      <td>297.00482</td>\n      <td>48.134129</td>\n      <td>15.436</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FALSE POSITIVE</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.736952</td>\n      <td>2.630000e-07</td>\n      <td>-2.630000e-07</td>\n      <td>170.307565</td>\n      <td>0.000115</td>\n      <td>...</td>\n      <td>-174</td>\n      <td>4.564</td>\n      <td>0.053</td>\n      <td>-0.168</td>\n      <td>0.791</td>\n      <td>0.201</td>\n      <td>-0.067</td>\n      <td>285.53461</td>\n      <td>48.285210</td>\n      <td>15.597</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.525592</td>\n      <td>3.760000e-06</td>\n      <td>-3.760000e-06</td>\n      <td>171.595550</td>\n      <td>0.001130</td>\n      <td>...</td>\n      <td>-211</td>\n      <td>4.438</td>\n      <td>0.070</td>\n      <td>-0.210</td>\n      <td>1.046</td>\n      <td>0.334</td>\n      <td>-0.133</td>\n      <td>288.75488</td>\n      <td>48.226200</td>\n      <td>15.509</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CONFIRMED</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4.134435</td>\n      <td>1.050000e-05</td>\n      <td>-1.050000e-05</td>\n      <td>172.979370</td>\n      <td>0.001900</td>\n      <td>...</td>\n      <td>-232</td>\n      <td>4.486</td>\n      <td>0.054</td>\n      <td>-0.229</td>\n      <td>0.972</td>\n      <td>0.315</td>\n      <td>-0.105</td>\n      <td>296.28613</td>\n      <td>48.224670</td>\n      <td>15.714</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 41 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Read in the csv file\n",
    "df = pd.read_csv('../data/exoplanet_data.csv')\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following is a scaled score of the features at n_estimators=10\n[0.13529846 0.16541872 0.12979329 0.04708777 0.0195375  0.01478677\n 0.0153534  0.01220135 0.0209395  0.023102   0.01201981 0.01151099\n 0.00956523 0.01719395 0.02967806 0.02664136 0.02140882 0.01214155\n 0.01185653 0.012489   0.01162835 0.0113699  0.01568997 0.00973773\n 0.0092699  0.00845838 0.03284808 0.00930861 0.01020008 0.01959437\n 0.0195308  0.01072367 0.00995833 0.01427395 0.00823315 0.01183016\n 0.00856637 0.01085899 0.01019785 0.00969731]\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction, bind class to an object\n",
    "# n_estimators are the number of trees in the forest\n",
    "model1 = ExtraTreesClassifier(n_estimators=10)\n",
    "# Fit the arrays with the model\n",
    "model1.fit(X,y)\n",
    "print('The following is a scaled score of the features at n_estimators=10')\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The following is a scaled score of the features at n_estimators=100\n[0.13529846 0.16541872 0.12979329 0.04708777 0.0195375  0.01478677\n 0.0153534  0.01220135 0.0209395  0.023102   0.01201981 0.01151099\n 0.00956523 0.01719395 0.02967806 0.02664136 0.02140882 0.01214155\n 0.01185653 0.012489   0.01162835 0.0113699  0.01568997 0.00973773\n 0.0092699  0.00845838 0.03284808 0.00930861 0.01020008 0.01959437\n 0.0195308  0.01072367 0.00995833 0.01427395 0.00823315 0.01183016\n 0.00856637 0.01085899 0.01019785 0.00969731]\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction, bind class to an object\n",
    "# n_estimators are the number of trees in the forest\n",
    "model2 = ExtraTreesClassifier(n_estimators=100)\n",
    "# Fit the arrays with the model\n",
    "model2.fit(X,y)\n",
    "print('The following is a scaled score of the features at n_estimators=100')\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    feature_num       feature name      n=10     n=100\n",
       "1             2      koi_fpflag_ss  0.184764  0.170404\n",
       "0             1      koi_fpflag_nt  0.132146  0.130664\n",
       "2             3      koi_fpflag_co  0.124189  0.130066\n",
       "3             4      koi_fpflag_ec  0.060071  0.048735\n",
       "26           27      koi_model_snr  0.021988  0.035516\n",
       "15           16  koi_duration_err2  0.029898  0.027527\n",
       "14           15  koi_duration_err1  0.023821  0.026958\n",
       "16           17          koi_depth  0.023751  0.024574\n",
       "8             9   koi_time0bk_err1  0.019330  0.021142\n",
       "9            10   koi_time0bk_err2  0.020631  0.020783"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_num</th>\n      <th>feature name</th>\n      <th>n=10</th>\n      <th>n=100</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>koi_fpflag_ss</td>\n      <td>0.184764</td>\n      <td>0.170404</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>koi_fpflag_nt</td>\n      <td>0.132146</td>\n      <td>0.130664</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>koi_fpflag_co</td>\n      <td>0.124189</td>\n      <td>0.130066</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>koi_fpflag_ec</td>\n      <td>0.060071</td>\n      <td>0.048735</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>koi_model_snr</td>\n      <td>0.021988</td>\n      <td>0.035516</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>koi_duration_err2</td>\n      <td>0.029898</td>\n      <td>0.027527</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>koi_duration_err1</td>\n      <td>0.023821</td>\n      <td>0.026958</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>koi_depth</td>\n      <td>0.023751</td>\n      <td>0.024574</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>koi_time0bk_err1</td>\n      <td>0.019330</td>\n      <td>0.021142</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>koi_time0bk_err2</td>\n      <td>0.020631</td>\n      <td>0.020783</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# Rank the outcomes by n_estimators\n",
    "feature_num = np.arange(1, 41, 1)\n",
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature name' : df.columns[1:],\n",
    "    'n=10' : model1.feature_importances_, \n",
    "    'n=100' : model2.feature_importances_}\n",
    "etc_rank = pd.DataFrame(dict)\n",
    "etc_rank.sort_values(by='n=100', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "## Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
    "\n",
    "The scikit-learn library provides the [SelectKBest](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest) class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "\n",
    "Many different statistical test scan be used with this selection method. For example the ANOVA F-value method is appropriate for numerical inputs and categorical data, as we see in the Pima dataset. This can be used via the [f_classif()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html) function. We will select the 4 best features using this method in the example below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[7.369e+02 1.433e+03 1.159e+03 5.761e+02 7.936e+01 6.782e+01 6.782e+01\n 1.901e+01 8.222e+01 8.222e+01 2.233e+01 4.641e+01 6.841e-01 9.614e+01\n 1.158e+02 1.158e+02 2.781e+02 1.609e+00 1.609e+00 3.701e+00 5.724e+00\n 2.882e+00 2.767e+02 3.354e+00 6.785e+00 2.537e+00 2.318e+02 1.677e+02\n 1.332e+02 6.494e+02 4.999e+02 9.147e+01 8.711e+01 2.340e+02 1.968e+01\n 6.505e+01 2.490e+01 1.042e+02 4.267e+01 1.194e+01]\n[[0 0 0 0 81]\n [0 1 0 0 158]\n [0 1 0 0 157]\n [0 0 0 0 169]\n [0 0 0 0 189]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "test = SelectKBest(score_func=f_classif, k=5)\n",
    "fit = test.fit(X, y)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    feature_num    feature_name   fit_scores\n",
       "1             2   koi_fpflag_ss  1432.706256\n",
       "2             3   koi_fpflag_co  1159.458615\n",
       "0             1   koi_fpflag_nt   736.896271\n",
       "29           30  koi_steff_err1   649.421795\n",
       "3             4   koi_fpflag_ec   576.060340\n",
       "30           31  koi_steff_err2   499.942313\n",
       "16           17       koi_depth   278.062703\n",
       "22           23         koi_teq   276.736364\n",
       "33           34  koi_slogg_err2   234.049828\n",
       "26           27   koi_model_snr   231.814329"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_num</th>\n      <th>feature_name</th>\n      <th>fit_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>koi_fpflag_ss</td>\n      <td>1432.706256</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>koi_fpflag_co</td>\n      <td>1159.458615</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>koi_fpflag_nt</td>\n      <td>736.896271</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>koi_steff_err1</td>\n      <td>649.421795</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>koi_fpflag_ec</td>\n      <td>576.060340</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>31</td>\n      <td>koi_steff_err2</td>\n      <td>499.942313</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>koi_depth</td>\n      <td>278.062703</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>koi_teq</td>\n      <td>276.736364</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>34</td>\n      <td>koi_slogg_err2</td>\n      <td>234.049828</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>koi_model_snr</td>\n      <td>231.814329</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature_name' : df.columns[1:],\n",
    "    'fit_scores' : fit.scores_\n",
    "    }\n",
    "etc_rank = pd.DataFrame(dict)\n",
    "etc_rank.sort_values(by='fit_scores', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "## Recursive Feature Elimination\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\n",
    "\n",
    "It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
    "\n",
    "You can learn more about the [RFE](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) class in the scikit-learn documentation.\n",
    "\n",
    "The example below uses RFE with the logistic regression algorithm to select the top 3 features. The choice of algorithm does not matter too much as long as it is skillful and consistent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num Features: 6\nSelected Features: [False False False False  True False False False False False False False\n False False False False False False False  True  True  True False False\n False False False False False  True False False False False False False\n False  True False False]\nFeature Ranking: [18 22 16 21  1 34 35  2 33 32 24 13 30 14 19 20 12  5  4  1  1  1  6 11\n  9 10  3 25  8  1  7 26 31 29 23 28 27  1 15 17]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "rfe = RFE(model, 6)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    feature_num    feature_name  best_fit\n",
       "4             5      koi_period      True\n",
       "19           20        koi_prad      True\n",
       "20           21   koi_prad_err1      True\n",
       "21           22   koi_prad_err2      True\n",
       "29           30  koi_steff_err1      True\n",
       "37           38              ra      True"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_num</th>\n      <th>feature_name</th>\n      <th>best_fit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>koi_period</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>koi_prad</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>koi_prad_err1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>koi_prad_err2</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>30</td>\n      <td>koi_steff_err1</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>38</td>\n      <td>ra</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "dict = {\n",
    "    'feature_num' : feature_num,\n",
    "    'feature_name' : df.columns[1:],\n",
    "    'best_fit' : fit.support_\n",
    "    }\n",
    "feature_rfe = pd.DataFrame(dict)\n",
    "is_true = feature_rfe['best_fit'] == True\n",
    "feature_rfe[is_true]"
   ]
  },
  {
   "source": [
    "##Principal Component Analysis\n",
    "[Principal Component Analysis](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/) (or PCA) uses linear algebra to transform the dataset into a compressed form.\n",
    "\n",
    "Generally this is called a data reduction technique. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result.\n",
    "\n",
    "In the example below, we use PCA and select 3 principal components.\n",
    "\n",
    "Learn more about the [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) class in scikit-learn by reviewing the PCA API. Dive deeper into the math behind PCA on the [Principal Component Analysis Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis) article."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Explained Variance: [0.848 0.132 0.012]\n[[ 2.244e-09  6.082e-08  3.256e-08  5.484e-08 -1.247e-05 -4.111e-10\n   4.111e-10 -6.973e-06 -2.838e-10  2.838e-10 -5.801e-08 -3.463e-07\n   2.671e-08 -5.446e-07 -2.058e-08  2.058e-08 -2.576e-03 -2.651e-05\n   2.651e-05  3.852e-05  3.189e-06 -7.064e-06  1.770e-03  8.492e-01\n   2.500e-01 -4.651e-01 -3.421e-05 -2.340e-08 -2.165e-04 -7.142e-06\n   4.967e-06 -5.892e-07  1.670e-08  9.538e-09  1.599e-05  1.399e-06\n  -4.987e-06  5.539e-07 -2.887e-07 -4.588e-07]\n [-1.936e-07  2.211e-06 -6.481e-07 -3.522e-07 -9.176e-05 -6.029e-09\n   6.029e-09 -3.027e-05 -2.944e-08  2.944e-08  4.351e-08 -4.875e-06\n   9.046e-07  5.669e-06 -9.978e-07  9.978e-07  9.998e-01  1.436e-02\n  -1.436e-02  3.227e-05  5.025e-05  2.442e-06  8.199e-04  9.640e-04\n   7.649e-04 -3.366e-03  5.891e-03 -7.439e-07  1.210e-03  9.067e-05\n  -1.257e-04 -6.323e-08  1.727e-07 -2.656e-08 -9.706e-07 -1.100e-08\n  -4.614e-08  1.133e-06 -7.096e-07  3.119e-08]\n [-2.404e-07 -4.450e-07 -2.874e-07 -4.665e-07  7.899e-05  2.686e-09\n  -2.686e-09  3.736e-05  1.153e-08 -1.153e-08  3.012e-08  2.107e-06\n  -3.193e-07  1.479e-06  1.685e-07 -1.685e-07 -1.839e-03 -1.522e-04\n   1.522e-04 -3.679e-04 -6.447e-05  4.402e-05 -4.408e-03 -2.326e-01\n  -6.137e-01 -7.545e-01 -4.797e-06  2.738e-07  4.126e-04 -1.681e-05\n  -1.245e-05  1.977e-06 -1.941e-08  2.033e-08 -1.034e-05 -6.308e-06\n  -1.647e-05  2.123e-06 -6.707e-08  1.901e-06]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# Create an array from the values in the dataframe values\n",
    "array = df.values\n",
    "# Pull out features and labels from the columns with slice \n",
    "X= array[:, 1:]\n",
    "y= array[:, 0]"
   ]
  }
 ]
}